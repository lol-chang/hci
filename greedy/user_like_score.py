import os
import json
import numpy as np
import pandas as pd
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

import weaviate
from weaviate.auth import AuthApiKey
from weaviate.classes import query as wq


# ========== CONFIG ==========
CONFIG = {
    "USER_FILE": r"C:\Users\changjin\workspace\lab\pln\data_set\1000_user_info.csv",
    "OUTPUT_DIR": r"C:\Users\changjin\workspace\lab\pln\vector_embedding\pure_preference_only",
}

CATEGORY_FILES = {
    "Accommodation": "accommodations_fixed.csv",
    "ì¹´í˜": "cafe_fixed.csv",
    "ìŒì‹ì ": "restaurants_fixed.csv",
    "ê´€ê´‘ì§€": "attractions_fixed.csv"
}

# ì¹´í…Œê³ ë¦¬ í•œê¸€ â†’ ì˜ì–´ ë³€í™˜ ë§¤í•‘
CATEGORY_TRANSLATE = {
    "Accommodation": "Accommodation",
    "ì¹´í˜": "Cafe",
    "ìŒì‹ì ": "Restaurant",
    "ê´€ê´‘ì§€": "Attraction"
}


# ========== 1. í™˜ê²½ ë³€ìˆ˜ ë° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ==========
print("ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë”©...")
load_dotenv()

api_key = os.getenv("WEAVIATE_API_KEY")
cluster_url = os.getenv("WEAVIATE_CLUSTER_URL")

client = weaviate.connect_to_weaviate_cloud(
    cluster_url=cluster_url,
    auth_credentials=AuthApiKey(api_key)
)
print("âœ… Weaviate ì—°ê²° ì™„ë£Œ\n")

collection = client.collections.get("Place")


# ========== 2. ëª¨ë¸ ë¡œë“œ ==========
model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")


# ========== 3. ì „ì²´ ì¥ì†Œ ì ìˆ˜ ë§¤ê¸°ê¸° (í•„í„°ë§ ì—†ìŒ) ==========
def score_all_places(user_like_vec, user_dislike_vecs, category_name, alpha=1.0, beta=0.5):
    """
    ì „ì²´ ì¥ì†Œì— ëŒ€í•´ ì„ í˜¸ë„ ì ìˆ˜ë§Œ ë§¤ê¸°ëŠ” í•¨ìˆ˜
    - í•„í„°ë§ ì—†ìŒ (dislike_threshold ì‚¬ìš© ì•ˆ í•¨)
    - Top-K ì œí•œ ì—†ìŒ (ëª¨ë“  ì¥ì†Œ í¬í•¨)
    - ìˆœìˆ˜í•˜ê²Œ ì ìˆ˜ë§Œ ê³„ì‚°
    """
    results = collection.query.near_vector(
        near_vector=user_like_vec.tolist(),
        limit=4000,  # Weaviate ìµœëŒ€ ì œí•œ
        return_metadata=["distance"],
        include_vector=True,
        filters=wq.Filter.by_property("category").equal(category_name)
    )

    scored = []
    seen_place_ids = set()  # ì¤‘ë³µ ë°©ì§€

    for obj in results.objects:
        pid = obj.properties.get("place_id")
        if pid in seen_place_ids:
            continue
        seen_place_ids.add(pid)

        # Like ìœ ì‚¬ë„ ê³„ì‚°
        like_sim = 1 - obj.metadata.distance

        # Dislike ìœ ì‚¬ë„ ê³„ì‚°
        place_dislike_vec = obj.properties.get("dislike_embedding", [])
        max_dislike_sim = 0
        if place_dislike_vec and user_dislike_vecs:
            sims = [
                cosine_similarity([ud], [place_dislike_vec])[0][0]
                for ud in user_dislike_vecs if len(ud) > 0
            ]
            max_dislike_sim = max(sims) if sims else 0

        # ìµœì¢… ì ìˆ˜: Like - Dislike (ìˆœìˆ˜ ì„ í˜¸ë„ë§Œ)
        # âœ… í•„í„°ë§ ì—†ìŒ, ìŒìˆ˜ë„ ê·¸ëŒ€ë¡œ ìœ ì§€
        preference_score = alpha * like_sim - beta * max_dislike_sim
        
        scored.append((pid, preference_score))

    # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ë†’ì€ ì ìˆ˜ê°€ ì•ìœ¼ë¡œ)
    scored.sort(key=lambda x: x[1], reverse=True)
    
    # âœ… Top-K ì œí•œ ì—†ì´ ì „ì²´ ë°˜í™˜
    return scored


# ========== 4. ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ==========
def format_results(results_by_cat):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    final_scores = {}
    
    for cat, scored_list in results_by_cat.items():
        if not scored_list:
            continue
        
        # IDì™€ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        cat_list = [
            {
                "id": pid,
                "preference_score": float(score)
            }
            for pid, score in scored_list
        ]
        
        # ì˜ì–´ ì¹´í…Œê³ ë¦¬ëª…ìœ¼ë¡œ ì €ì¥
        final_scores[CATEGORY_TRANSLATE[cat]] = cat_list
    
    return final_scores


# ========== 5. ëª¨ë“  ìœ ì € ì²˜ë¦¬ ==========
user_df = pd.read_csv(CONFIG["USER_FILE"])
os.makedirs(CONFIG["OUTPUT_DIR"], exist_ok=True)

print(f"\n{'='*70}")
print(f"ğŸš€ ì „ì²´ ì¥ì†Œ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° ì‹œì‘ (í•„í„°ë§ ì—†ìŒ)")
print(f"{'='*70}\n")

for idx, user in user_df.iterrows():
    user_id = user["user_id"]
    like_keywords = eval(user["like_keywords"])
    dislike_keywords = eval(user["dislike_keywords"])

    print(f"ğŸ‘¤ Processing User {idx+1}/{len(user_df)} â†’ {user_id}")
    print(f"   ğŸ‘ like: {like_keywords}")
    print(f"   ğŸ‘ dislike: {dislike_keywords}")

    # ìœ ì € ì„ í˜¸ë„ ë²¡í„° ìƒì„±
    user_like_vec = model.encode(" ".join(like_keywords), convert_to_numpy=True)
    user_dislike_vecs = [model.encode(kw, convert_to_numpy=True) for kw in dislike_keywords]

    # ì¹´í…Œê³ ë¦¬ë³„ ì „ì²´ ì¥ì†Œ ì ìˆ˜ ê³„ì‚°
    results_by_cat = {}
    for cat in CATEGORY_FILES.keys():
        results = score_all_places(
            user_like_vec, 
            user_dislike_vecs,
            cat
        )
        results_by_cat[cat] = results
        
        # ì ìˆ˜ í†µê³„
        if results:
            scores = [score for _, score in results]
            print(f"   ğŸ“Š {CATEGORY_TRANSLATE[cat]}: {len(results)}ê°œ")
            print(f"      - ì ìˆ˜ ë²”ìœ„: {min(scores):.3f} ~ {max(scores):.3f}")
            print(f"      - í‰ê· : {sum(scores)/len(scores):.3f}")

    # JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    final_results = format_results(results_by_cat)

    # ìœ ì €ë³„ ê²°ê³¼ ì €ì¥
    out_path = os.path.join(CONFIG["OUTPUT_DIR"], f"{user_id}_recommendations_preference.json")
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(final_results, f, ensure_ascii=False, indent=2)

    print(f"âœ… {user_id} ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {out_path}\n")


# ========== 6. ì—°ê²° ì¢…ë£Œ ==========
client.close()
print(f"\n{'='*70}")
print("ğŸ”’ ì „ì²´ ìœ ì € ì²˜ë¦¬ ì™„ë£Œ & ì—°ê²° ì¢…ë£Œ")
print(f"{'='*70}")